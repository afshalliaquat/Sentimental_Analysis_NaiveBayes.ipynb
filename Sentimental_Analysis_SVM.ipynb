{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0+j+/E9YMu1HkJEHUSj9a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afshalliaquat/Sentimental_Analysis_NaiveBayes.ipynb/blob/main/Sentimental_Analysis_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IpS86sBY1Nv1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.txt',sep = ';',header=None,names= ['text','emotions'])"
      ],
      "metadata": {
        "id": "mKP7rxba1S3V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_emotions = df['emotions'].unique()\n",
        "emotion_no = {}\n",
        "i=0\n",
        "\n",
        "for emo in unique_emotions:\n",
        "  emotion_no[emo]=i\n",
        "  i+=1\n",
        "\n",
        "df['emotions'] = df['emotions'].map(emotion_no)"
      ],
      "metadata": {
        "id": "lPOYzojS1VPe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(lambda x:x.lower())"
      ],
      "metadata": {
        "id": "vgopS_CL1Wwf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "B54MBa0P1Yjo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(text):\n",
        "  return text.translate(str.maketrans('','',string.punctuation))"
      ],
      "metadata": {
        "id": "tv7wwDUR1aKo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove_punc)"
      ],
      "metadata": {
        "id": "hzsxNaoS1cL0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_no(text):\n",
        "  string = ''\n",
        "  for i in text:\n",
        "    if not i.isdigit():\n",
        "      string += i\n",
        "  return string\n"
      ],
      "metadata": {
        "id": "F0eZPE2K1eai"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove_no)"
      ],
      "metadata": {
        "id": "zuevTEJ91gdy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text):\n",
        "  string = ''\n",
        "  for i in text:\n",
        "    if i.isascii():\n",
        "      string+=i\n",
        "  return string"
      ],
      "metadata": {
        "id": "V2i6BVXW1jGc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove_emoji)"
      ],
      "metadata": {
        "id": "aaiXQXN-1lDK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "PXiGEQqh1nPh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')       # for word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S1eXf-m1pZE",
        "outputId": "832fad55-14ea-4455-a80b-3d1963c96e9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "WmbvtxbX1rTQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove(txt):\n",
        "  words = txt.split()\n",
        "  cleaned = []\n",
        "  for i in words:\n",
        "    if not i in stop_words:\n",
        "      cleaned.append(i)\n",
        "  return ' '.join(cleaned)"
      ],
      "metadata": {
        "id": "23oBMxvl1uUQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove)"
      ],
      "metadata": {
        "id": "jkmLmgx21wS7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "f29hb2k61yq_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y= df['emotions']"
      ],
      "metadata": {
        "id": "HkQbzk9e142T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "nd8DJ5Qp16sH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer  #Bag of words (only 0 and 1s)"
      ],
      "metadata": {
        "id": "TxY7xsgh12R1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = CountVectorizer()\n",
        "X_train_bow = bow.fit_transform(X_train)\n",
        "X_test_bow = bow.transform(X_test)"
      ],
      "metadata": {
        "id": "zBdd4Itt1883"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_vector = vectorizer.fit_transform(X_train)\n",
        "X_test_vector = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "8_Blz0Fa1_Kt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model_svm_tfid = SVC()\n",
        "model_svm_tfid.fit(X_train_vector, y_train)\n",
        "y_pred_tfid = model_svm_tfid.predict(X_test_vector)\n",
        "accuracy_score(y_test,y_pred_tfid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f83kmK83iyj",
        "outputId": "f2c56fa3-08a1-4ba7-cbb1-14d5e430a324"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85125"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Parameter_SVM = {\n",
        "    'C': [0.1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "}"
      ],
      "metadata": {
        "id": "Jn9lSqGk3ktD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM_para_tfid = RandomizedSearchCV(estimator=model_svm_tfid,n_iter=5,cv=5,param_distributions=Parameter_SVM)\n",
        "# SVM_para_tfid.fit(X_train_vector,y_train)\n",
        "# new_model_tfid =SVM_para_tfid.best_estimator_\n",
        "# y_pre_tfid = new_model_tfid.predict(X_test_vector)\n",
        "# accuracy_score(y_test,y_pre_tfid)"
      ],
      "metadata": {
        "id": "nysoIK7Z3pHz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model_svm_bow = SVC()\n",
        "model_svm_bow.fit(X_train_bow, y_train)\n",
        "y_pred_bow = model_svm_bow.predict(X_test_bow)\n",
        "accuracy_score(y_test,y_pred_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPJcpQHe6xxa",
        "outputId": "7f07695c-536b-4834-af09-4126d39c4259"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8225"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM_para_bow = RandomizedSearchCV(estimator=model_svm_bow,n_iter=5,cv=5,param_distributions=Parameter_SVM)\n",
        "# SVM_para_bow.fit(X_train_vector,y_train)\n",
        "# new_model_svm_bow =SVM_para_bow.best_estimator_\n",
        "# y_pre_bow = new_model_svm_bow.predict(X_test_vector)\n",
        "# accuracy_score(y_test,y_pre_bow)"
      ],
      "metadata": {
        "id": "5jNx7K7K60W9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_tfid))\n",
        "print(classification_report(y_test, y_pred_bow))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piFxRDi851hI",
        "outputId": "b1a5a91a-e21c-41fa-c6a0-8205e761444a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.91       946\n",
            "           1       0.91      0.81      0.85       427\n",
            "           2       0.89      0.55      0.68       296\n",
            "           3       0.84      0.51      0.64       113\n",
            "           4       0.85      0.75      0.80       397\n",
            "           5       0.79      0.96      0.87      1021\n",
            "\n",
            "    accuracy                           0.85      3200\n",
            "   macro avg       0.86      0.75      0.79      3200\n",
            "weighted avg       0.86      0.85      0.85      3200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.90       946\n",
            "           1       0.90      0.72      0.80       427\n",
            "           2       0.88      0.51      0.65       296\n",
            "           3       0.84      0.45      0.59       113\n",
            "           4       0.84      0.70      0.77       397\n",
            "           5       0.74      0.96      0.83      1021\n",
            "\n",
            "    accuracy                           0.82      3200\n",
            "   macro avg       0.85      0.71      0.76      3200\n",
            "weighted avg       0.84      0.82      0.82      3200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}