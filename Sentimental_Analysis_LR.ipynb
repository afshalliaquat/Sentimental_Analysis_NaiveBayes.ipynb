{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHqBo10OaONGEwIV9LON8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afshalliaquat/Sentimental_Analysis_NaiveBayes.ipynb/blob/main/Sentimental_Analysis_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IpS86sBY1Nv1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.txt',sep = ';',header=None,names= ['text','emotions'])"
      ],
      "metadata": {
        "id": "mKP7rxba1S3V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_emotions = df['emotions'].unique()\n",
        "emotion_no = {}\n",
        "i=0\n",
        "\n",
        "for emo in unique_emotions:\n",
        "  emotion_no[emo]=i\n",
        "  i+=1\n",
        "\n",
        "df['emotions'] = df['emotions'].map(emotion_no)"
      ],
      "metadata": {
        "id": "lPOYzojS1VPe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(lambda x:x.lower())"
      ],
      "metadata": {
        "id": "vgopS_CL1Wwf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "B54MBa0P1Yjo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(text):\n",
        "  return text.translate(str.maketrans('','',string.punctuation))"
      ],
      "metadata": {
        "id": "tv7wwDUR1aKo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove_punc)"
      ],
      "metadata": {
        "id": "hzsxNaoS1cL0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_no(text):\n",
        "  string = ''\n",
        "  for i in text:\n",
        "    if not i.isdigit():\n",
        "      string += i\n",
        "  return string\n"
      ],
      "metadata": {
        "id": "F0eZPE2K1eai"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove_no)"
      ],
      "metadata": {
        "id": "zuevTEJ91gdy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text):\n",
        "  string = ''\n",
        "  for i in text:\n",
        "    if i.isascii():\n",
        "      string+=i\n",
        "  return string"
      ],
      "metadata": {
        "id": "V2i6BVXW1jGc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove_emoji)"
      ],
      "metadata": {
        "id": "aaiXQXN-1lDK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "PXiGEQqh1nPh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')       # for word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S1eXf-m1pZE",
        "outputId": "7f73c8f9-35af-4cf3-b21f-fae83723b0db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "WmbvtxbX1rTQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove(txt):\n",
        "  words = txt.split()\n",
        "  cleaned = []\n",
        "  for i in words:\n",
        "    if not i in stop_words:\n",
        "      cleaned.append(i)\n",
        "  return ' '.join(cleaned)"
      ],
      "metadata": {
        "id": "23oBMxvl1uUQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(remove)"
      ],
      "metadata": {
        "id": "jkmLmgx21wS7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "f29hb2k61yq_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y= df['emotions']"
      ],
      "metadata": {
        "id": "HkQbzk9e142T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "nd8DJ5Qp16sH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer  #Bag of words (only 0 and 1s)"
      ],
      "metadata": {
        "id": "TxY7xsgh12R1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow = CountVectorizer()\n",
        "X_train_bow = bow.fit_transform(X_train)\n",
        "X_test_bow = bow.transform(X_test)"
      ],
      "metadata": {
        "id": "zBdd4Itt1883"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_vector = vectorizer.fit_transform(X_train)\n",
        "X_test_vector = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "8_Blz0Fa1_Kt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "model_LR = LogisticRegression(max_iter=1000)\n",
        "model_LR.fit(X_train_vector, y_train)\n",
        "y_pred_LR = model_LR.predict(X_test_vector)\n",
        "accuracy_score(y_test,y_pred_LR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnHjbvBP3XKi",
        "outputId": "6a63929d-3d00-4f67-8e4b-5e5114c9cc54"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8628125"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Parameter_LR = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],     # C is for regularization strength\n",
        "    'penalty': ['l2'],                # Only l2 works with most solvers\n",
        "}"
      ],
      "metadata": {
        "id": "NvhpGgXV3Z9s"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_para = RandomizedSearchCV(estimator=model_LR,cv=5,n_iter=5,param_distributions=Parameter_LR)\n",
        "LR_para.fit(X_train_vector,y_train)\n",
        "new_model_LR =LR_para.best_estimator_\n",
        "y_pre = new_model_LR.predict(X_test_vector)\n",
        "accuracy_score(y_test,y_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyR0h68k3cmg",
        "outputId": "45502b75-0161-449f-8d8d-24dc1390f763"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88125"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_LR_bow = LogisticRegression(max_iter=1000)\n",
        "model_LR_bow.fit(X_train_bow, y_train)\n",
        "y_pred_LR_bow = model_LR_bow.predict(X_test_bow)\n",
        "accuracy_score(y_test,y_pred_LR_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy_kGYZN30Mh",
        "outputId": "ea360a50-d3e2-4307-8ba2-dc0ef8c534eb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8896875"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_para_bow = RandomizedSearchCV(estimator=model_LR_bow,cv=5,n_iter=5,param_distributions=Parameter_LR)\n",
        "LR_para_bow.fit(X_train_bow,y_train)\n",
        "new_model_LR_bow =LR_para_bow.best_estimator_\n",
        "y_pre_bow = new_model_LR_bow.predict(X_test_bow)\n",
        "accuracy_score(y_test,y_pre_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUoNnxvK31qQ",
        "outputId": "97b1ed1a-f868-47f1-f107-3c5a87908e47"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8896875"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_LR_bow))\n",
        "print(classification_report(y_test, y_pred_LR))\n",
        "print(classification_report(y_test, y_pre_bow))\n",
        "print(classification_report(y_test, y_pre))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCz4ffTc6PP1",
        "outputId": "704f4c86-f1d9-414d-d775-5630c5eaebbf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       946\n",
            "           1       0.89      0.86      0.87       427\n",
            "           2       0.85      0.76      0.80       296\n",
            "           3       0.86      0.73      0.79       113\n",
            "           4       0.86      0.84      0.85       397\n",
            "           5       0.88      0.94      0.91      1021\n",
            "\n",
            "    accuracy                           0.89      3200\n",
            "   macro avg       0.88      0.84      0.86      3200\n",
            "weighted avg       0.89      0.89      0.89      3200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       946\n",
            "           1       0.90      0.81      0.86       427\n",
            "           2       0.90      0.61      0.73       296\n",
            "           3       0.88      0.47      0.61       113\n",
            "           4       0.86      0.76      0.81       397\n",
            "           5       0.81      0.96      0.88      1021\n",
            "\n",
            "    accuracy                           0.86      3200\n",
            "   macro avg       0.88      0.76      0.80      3200\n",
            "weighted avg       0.87      0.86      0.86      3200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       946\n",
            "           1       0.89      0.86      0.87       427\n",
            "           2       0.85      0.76      0.80       296\n",
            "           3       0.86      0.73      0.79       113\n",
            "           4       0.86      0.84      0.85       397\n",
            "           5       0.88      0.94      0.91      1021\n",
            "\n",
            "    accuracy                           0.89      3200\n",
            "   macro avg       0.88      0.84      0.86      3200\n",
            "weighted avg       0.89      0.89      0.89      3200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93       946\n",
            "           1       0.89      0.86      0.87       427\n",
            "           2       0.85      0.71      0.77       296\n",
            "           3       0.84      0.62      0.71       113\n",
            "           4       0.85      0.82      0.84       397\n",
            "           5       0.86      0.95      0.90      1021\n",
            "\n",
            "    accuracy                           0.88      3200\n",
            "   macro avg       0.87      0.81      0.84      3200\n",
            "weighted avg       0.88      0.88      0.88      3200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(models['model_LR'],'LR_sentamental_analysis.pkl')\n",
        "joblib.dump(scaler,'scaler.pkl')\n",
        "joblib.dump(x.columns.to_list(),'columns.pkl')"
      ],
      "metadata": {
        "id": "egOQHyBI71_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}